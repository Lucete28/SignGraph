import os
import yaml
import torch
import whisper
import utils
import random
import shutil
import inspect
import numpy as np
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from modules.resnet import resnet18  # ì˜ˆì œì—ì„œëŠ” resnet18 ì‚¬ìš©
from modules import BiLSTMLayer, TemporalConv

class FeatureExtractor(nn.Module):
    """ ê¸°ì¡´ ëª¨ë¸ì—ì„œ CNN + 1D Conv + BiLSTM ë¶€ë¶„ì„ ë¡œë“œí•˜ì—¬ íŠ¹ì§• ì¶”ì¶œ """
    def __init__(self, model_path, num_classes, c2d_type="resnet18", conv_type="1d", hidden_size=1024):
        super(FeatureExtractor, self).__init__()

        # 2D CNN Feature Extractor
        self.conv2d = resnet18()  
        self.conv2d.fc = nn.Identity()

        # 1D Temporal Convolution
        self.conv1d = TemporalConv(input_size=512, hidden_size=hidden_size,
                                   conv_type=conv_type, use_bn=False,
                                   num_classes=num_classes)
        self.conv1d.kernel_size = [3, 5, 7]  # ğŸ”¥ ì˜¤ë¥˜ ìˆ˜ì •: kernel_size ì†ì„± ì¶”ê°€

        # BiLSTM Temporal Model
        self.temporal_model = BiLSTMLayer(rnn_type='LSTM', input_size=hidden_size, 
                                          hidden_size=hidden_size, num_layers=2, 
                                          bidirectional=True)

        # ê¸°ì¡´ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        self.load_pretrained_model(model_path)

    def load_pretrained_model(self, model_path):
        """ ê¸°ì¡´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ classifier ì´ì „ê¹Œì§€ë§Œ ì‚¬ìš© """
        print(f"Loading pretrained model from {model_path}")
        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
        
        # ê¸°ì¡´ ëª¨ë¸ì—ì„œ classifier ë¶€ë¶„ì„ ì œì™¸í•˜ê³  ë¶ˆëŸ¬ì˜´
        model_dict = checkpoint['model_state_dict']
        feature_extract_keys = {k: v for k, v in model_dict.items() if "classifier" not in k}

        self.load_state_dict(feature_extract_keys, strict=False)

        # íŠ¹ì§• ì¶”ì¶œ ë¶€ë¶„ í•™ìŠµ ì•ˆë˜ë„ë¡ ê³ ì • (freeze)
        for param in self.conv2d.parameters():
            param.requires_grad = False
        for param in self.conv1d.parameters():
            param.requires_grad = False
        for param in self.temporal_model.parameters():
            param.requires_grad = False

        print("Feature extractor loaded and frozen.")

    def forward(self, x, len_x):
        with torch.no_grad():
            # CNN íŠ¹ì§• ì¶”ì¶œ
            if len(x.shape) == 5:
                batch, temp, channel, height, width = x.shape
                framewise = self.conv2d(x.permute(0, 2, 1, 3, 4)).view(batch, temp, -1).permute(0, 2, 1)
            else:
                framewise = x

            # 1D Conv ì²˜ë¦¬
            conv1d_outputs = self.conv1d(framewise, len_x)
            x = conv1d_outputs['visual_feat']
            lgt = conv1d_outputs['feat_len'].cpu()

            # BiLSTM ì²˜ë¦¬
            tm_outputs = self.temporal_model(x, lgt)

        return tm_outputs['predictions'], lgt


class WhisperSLRModel(nn.Module):
    """ Whisper ë””ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ gloss ì˜ˆì¸¡ """
    def __init__(self, num_classes, hidden_size=1024):
        super(WhisperSLRModel, self).__init__()

        # Whisper ë””ì½”ë” ë¡œë“œ
        whisper_model = whisper.load_model("base")  
        self.whisper_decoder = whisper_model.decoder  

        # Gloss í† í° ì„ë² ë”© ë° ë¶„ë¥˜ê¸°
        self.token_embedding = nn.Embedding(num_classes, hidden_size)  
        self.output_proj = nn.Linear(hidden_size, num_classes)  

    def forward(self, feature_inputs, label=None):
        decoder_input = feature_inputs.permute(1, 0, 2)  # WhisperëŠ” (B, T, C) í˜•ì‹ ê¸°ëŒ€
        
        # Gloss í† í° ì„ë² ë”©
        if label is not None:
            label_embedding = self.token_embedding(label)  
        else:
            label_embedding = torch.zeros_like(decoder_input)  

        # Whisper ë””ì½”ë” ì ìš©
        decoder_output = self.whisper_decoder(x=decoder_input, xa=label_embedding)

        # ìµœì¢… gloss ì˜ˆì¸¡
        gloss_logits = self.output_proj(decoder_output)  
        return gloss_logits


def build_dataloader(args, dataset, mode, train_flag):
    """ Processorì˜ ë°ì´í„° ë¡œë” ë¡œì§ì„ ì°¸ê³ í•˜ì—¬ ë°ì´í„° ë¡œë” ìƒì„± """
    batch_size = args.batch_size if mode == "train" else args.test_batch_size
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=train_flag,
        drop_last=train_flag,
        num_workers=args.num_worker,
        collate_fn=dataset.collate_fn,
        pin_memory=False
    )


def train(model, feature_extractor, dataloader, optimizer, criterion, device):
    """ í•™ìŠµ ë£¨í”„ """
    model.train()
    total_loss = 0

    for batch in dataloader:
        videos, len_x, labels = batch
        videos, len_x, labels = videos.to(device), len_x.to(device), labels.to(device)

        # ê¸°ì¡´ ëª¨ë¸ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        feature_inputs, _ = feature_extractor(videos, len_x)

        # Whisper ê¸°ë°˜ gloss ì˜ˆì¸¡
        outputs = model(feature_inputs, label=labels)

        # Loss ê³„ì‚°
        loss = criterion(outputs.permute(1, 2, 0), labels)  
        total_loss += loss.item()

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    return total_loss / len(dataloader)


if __name__ == "__main__":
    # YAMLì—ì„œ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
    with open("configs/baseline.yaml", 'r') as f:
        args = yaml.load(f, Loader=yaml.FullLoader)

    num_classes = 500  
    hidden_size = 1024
    batch_size = 16
    learning_rate = 1e-4
    num_epochs = 10
    model_path = "_best_model.pt"

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # ê¸°ì¡´ ëª¨ë¸ì—ì„œ íŠ¹ì§• ì¶”ì¶œí•˜ëŠ” ë¶€ë¶„ë§Œ ë¡œë“œ
    feature_extractor = FeatureExtractor(model_path, num_classes)
    feature_extractor.to(device)

    # Whisper ê¸°ë°˜ SLR ëª¨ë¸ ìƒì„±
    slr_model = WhisperSLRModel(num_classes, hidden_size)
    slr_model.to(device)

    # ì˜µí‹°ë§ˆì´ì € & ì†ì‹¤ í•¨ìˆ˜
    optimizer = optim.Adam(slr_model.parameters(), lr=learning_rate)
    criterion = nn.CrossEntropyLoss()

    # ë°ì´í„° ë¡œë”
    dataset = utils.load_dataset(args)  
    train_loader = build_dataloader(args, dataset["train"], "train", True)

    # í•™ìŠµ ì‹œì‘
    for epoch in range(num_epochs):
        loss = train(slr_model, feature_extractor, train_loader, optimizer, criterion, device)
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}")

    # ìµœì¢… ëª¨ë¸ ì €ì¥
    torch.save(slr_model.state_dict(), "whisper_slr_model.pt")
