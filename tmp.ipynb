{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # <== ì—¬ê¸°ê°€ ì¤‘ìš”\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhy/.pyenv/versions/3.9.13/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import modules.resnet as resnet\n",
    "from modules import BiLSTMLayer, TemporalConv\n",
    "from modules.criterions import SeqKD\n",
    "import utils\n",
    "import modules.resnet as resnet\n",
    "# Identity Layer (ResNetì˜ Fully Connected ì œê±°ìš©)\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# L2 ì •ê·œí™” ì„ í˜• ë ˆì´ì–´\n",
    "class NormLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(NormLinear, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_dim, out_dim))\n",
    "        nn.init.xavier_uniform_(self.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = torch.matmul(x, F.normalize(self.weight, dim=0))\n",
    "        return outputs\n",
    "\n",
    "# SLRModel (ìˆ˜ì–´ ì¸ì‹ ëª¨ë¸)\n",
    "class SLRModel(nn.Module):\n",
    "    def __init__(\n",
    "            self, num_classes, c2d_type, conv_type, use_bn=False,\n",
    "            hidden_size=1024, gloss_dict=None, loss_weights=None,\n",
    "            weight_norm=True, share_classifier=True\n",
    "    ):\n",
    "        super(SLRModel, self).__init__()\n",
    "        self.decoder = None\n",
    "        self.loss = dict()\n",
    "        self.criterion_init()\n",
    "        self.num_classes = num_classes\n",
    "        self.loss_weights = loss_weights\n",
    "        self.conv2d = getattr(resnet, c2d_type)()  # ResNet ê¸°ë°˜ 2D CNN\n",
    "        self.conv2d.fc = Identity()  # Fully Connected ì œê±°\n",
    "\n",
    "        # 1D CNNì„ í™œìš©í•œ Temporal Encoding\n",
    "        self.conv1d = TemporalConv(input_size=512,\n",
    "                                   hidden_size=hidden_size,\n",
    "                                   conv_type=conv_type,\n",
    "                                   use_bn=use_bn,\n",
    "                                   num_classes=num_classes)\n",
    "\n",
    "        self.decoder = utils.Decode(gloss_dict, num_classes, 'beam')\n",
    "\n",
    "        # BiLSTM ê¸°ë°˜ Temporal Model\n",
    "        self.temporal_model = BiLSTMLayer(rnn_type='LSTM', input_size=hidden_size, hidden_size=hidden_size,\n",
    "                                          num_layers=2, bidirectional=True)\n",
    "\n",
    "        # Classifier (NormLinear ì‚¬ìš© ì—¬ë¶€ ê²°ì •)\n",
    "        if weight_norm:\n",
    "            self.classifier = NormLinear(hidden_size, self.num_classes)\n",
    "            self.conv1d.fc = NormLinear(hidden_size, self.num_classes)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(hidden_size, self.num_classes)\n",
    "            self.conv1d.fc = nn.Linear(hidden_size, self.num_classes)\n",
    "\n",
    "        # Classifier ê³µìœ  ì—¬ë¶€\n",
    "        if share_classifier:\n",
    "            self.conv1d.fc = self.classifier\n",
    "\n",
    "    def forward(self, x, len_x, label=None, label_lgt=None):\n",
    "        # CNNìœ¼ë¡œ Frame-wise Feature ì¶”ì¶œ\n",
    "        if len(x.shape) == 5:\n",
    "            batch, temp, channel, height, width = x.shape\n",
    "            framewise = self.conv2d(x.permute(0,2,1,3,4)).view(batch, temp, -1).permute(0,2,1)  # btc -> bct\n",
    "        else:\n",
    "            framewise = x\n",
    "\n",
    "        conv1d_outputs = self.conv1d(framewise, len_x)\n",
    "        x = conv1d_outputs['visual_feat']\n",
    "        lgt = conv1d_outputs['feat_len'].cpu()\n",
    "\n",
    "        # BiLSTMì„ í™œìš©í•œ Temporal Modeling\n",
    "        tm_outputs = self.temporal_model(x, lgt)\n",
    "        features_before_classifier = tm_outputs['predictions']  # âœ¨ ë¶„ë¥˜ê¸° ì „ íŠ¹ì§•ê°’ ì €ì¥\n",
    "\n",
    "        # ìµœì¢… Classifier ì ìš©\n",
    "        outputs = self.classifier(features_before_classifier)\n",
    "\n",
    "        # Inference ëª¨ë“œì—ì„œ Decoding\n",
    "        pred = None if self.training else self.decoder.decode(outputs, lgt, batch_first=False, probs=False)\n",
    "        conv_pred = None if self.training else self.decoder.decode(conv1d_outputs['conv_logits'], lgt, batch_first=False, probs=False)\n",
    "\n",
    "        return {\n",
    "            \"framewise_features\": framewise,\n",
    "            \"visual_features\": x,\n",
    "            \"temproal_features\": tm_outputs['predictions'],\n",
    "            \"feat_len\": lgt,\n",
    "            \"conv_logits\": conv1d_outputs['conv_logits'],\n",
    "            \"sequence_logits\": outputs,\n",
    "            \"features_before_classifier\": features_before_classifier,  # âœ¨ ì¶”ê°€ëœ ë¶€ë¶„\n",
    "            \"conv_sents\": conv_pred,\n",
    "            \"recognized_sents\": pred,\n",
    "        }\n",
    "\n",
    "    def criterion_init(self):\n",
    "        self.loss['CTCLoss'] = torch.nn.CTCLoss(reduction='none', zero_infinity=False)\n",
    "        self.loss['distillation'] = SeqKD(T=8)\n",
    "        return self.loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dataset_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(f, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mFullLoader)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# âœ… gloss_dict ë¡œë“œ\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m gloss_dict_path \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset_info\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# `dict_path`ëŠ” YAML íŒŒì¼ì— ì •ì˜ë¨\u001b[39;00m\n\u001b[1;32m     15\u001b[0m gloss_dict \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(gloss_dict_path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“Œ Gloss Dictionary Loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dataset_info'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "# âœ… config íŒŒì¼ ë¡œë“œ (dataset ì •ë³´ í¬í•¨)\n",
    "config_path = \"./configs/baseline.yaml\"  # í˜¹ì€ ì›í•˜ëŠ” ì„¤ì • íŒŒì¼\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# âœ… gloss_dict ë¡œë“œ\n",
    "gloss_dict_path = config[\"dataset_info\"][\"dict_path\"]  # `dict_path`ëŠ” YAML íŒŒì¼ì— ì •ì˜ë¨\n",
    "gloss_dict = np.load(gloss_dict_path, allow_pickle=True).item()\n",
    "\n",
    "print(\"ğŸ“Œ Gloss Dictionary Loaded!\")\n",
    "print(f\"Total Classes (Including Blank): {len(gloss_dict) + 1}\")\n",
    "print(f\"Sample Gloss Mapping: {list(gloss_dict.items())[:5]}\")  # ì¼ë¶€ë§Œ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSLRModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m226\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2d_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# conv_typeì€ tconv.pyì—ì„œ ì •ì˜ëœ ê°’ ì¤‘ í•˜ë‚˜ë¡œ ì„¤ì •\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_bn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgloss_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\u001b[39;00m\n\u001b[1;32m     10\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 53\u001b[0m, in \u001b[0;36mSLRModel.__init__\u001b[0;34m(self, num_classes, c2d_type, conv_type, use_bn, hidden_size, gloss_dict, loss_weights, weight_norm, share_classifier)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 1D CNNì„ í™œìš©í•œ Temporal Encoding\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d \u001b[38;5;241m=\u001b[39m TemporalConv(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     48\u001b[0m                            hidden_size\u001b[38;5;241m=\u001b[39mhidden_size,\n\u001b[1;32m     49\u001b[0m                            conv_type\u001b[38;5;241m=\u001b[39mconv_type,\n\u001b[1;32m     50\u001b[0m                            use_bn\u001b[38;5;241m=\u001b[39muse_bn,\n\u001b[1;32m     51\u001b[0m                            num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgloss_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# BiLSTM ê¸°ë°˜ Temporal Model\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_model \u001b[38;5;241m=\u001b[39m BiLSTMLayer(rnn_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m, input_size\u001b[38;5;241m=\u001b[39mhidden_size, hidden_size\u001b[38;5;241m=\u001b[39mhidden_size,\n\u001b[1;32m     57\u001b[0m                                   num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, bidirectional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/SignGraph/utils/decode.py:13\u001b[0m, in \u001b[0;36mDecode.__init__\u001b[0;34m(self, gloss_dict, num_classes, search_mode, blank_id, beam_width)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, gloss_dict, num_classes, search_mode, blank_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, beam_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi2g_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((v[\u001b[38;5;241m0\u001b[39m], k) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgloss_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m())\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg2i_dict \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi2g_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m=\u001b[39m num_classes\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = SLRModel(\n",
    "    num_classes=226, c2d_type=\"resnet18\", conv_type=2,  # conv_typeì€ tconv.pyì—ì„œ ì •ì˜ëœ ê°’ ì¤‘ í•˜ë‚˜ë¡œ ì„¤ì •\n",
    "    use_bn=True, hidden_size=1024, gloss_dict=None, loss_weights=None\n",
    ")\n",
    "\n",
    "# ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "state_dict = torch.load(\"model.pt\", map_location=\"cpu\")\n",
    "\n",
    "# state_dictê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸ í›„ ëª¨ë¸ì— ë¡œë“œ\n",
    "if isinstance(state_dict, dict):\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
